# Teste de Toler√¢ncia a Falhas e Performance

Este framework testa a capacidade de resili√™ncia e recupera√ß√£o do Apache Hadoop sob condi√ß√µes adversas, incluindo falhas de n√≥s e mudan√ßas din√¢micas na topologia do cluster.

## üìã Objetivo

Avaliar o comportamento do Hadoop quando:
- N√≥s workers falham durante a execu√ß√£o de jobs
- Novos n√≥s s√£o adicionados dinamicamente (scale up)
- M√∫ltiplas falhas simult√¢neas ocorrem
- Medir impacto na performance e capacidade de recupera√ß√£o

## üèóÔ∏è Estrutura do Framework

```
fault-tolerance/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ generate_data.sh      # Gera datasets de teste (500MB+)
‚îÇ   ‚îú‚îÄ‚îÄ upload_data.sh         # Upload dos dados para HDFS
‚îÇ   ‚îú‚îÄ‚îÄ monitor_job.sh         # Monitora jobs em tempo real
‚îÇ   ‚îî‚îÄ‚îÄ run_fault_test.sh      # Orquestra os testes de falha
‚îú‚îÄ‚îÄ data/                      # Dados gerados localmente
‚îú‚îÄ‚îÄ results/                   # Resultados dos testes
‚îî‚îÄ‚îÄ monitoring/                # Logs de monitoramento
```

## üöÄ Guia de Execu√ß√£o R√°pida

### 1. Preparar Dados de Teste

Gerar dataset de 500MB (padr√£o):
```bash
./fault-tolerance/scripts/generate_data.sh
```

Ou especificar tamanho customizado (em MB):
```bash
./fault-tolerance/scripts/generate_data.sh 1000  # 1GB
```

### 2. Upload para HDFS

```bash
./fault-tolerance/scripts/upload_data.sh
```

Verifica que os dados foram distribu√≠dos corretamente no cluster.

### 3. Executar Testes de Toler√¢ncia a Falhas

**Teste Individual:**
```bash
./fault-tolerance/scripts/run_fault_test.sh baseline          # Teste 1
./fault-tolerance/scripts/run_fault_test.sh worker-failure    # Teste 2
./fault-tolerance/scripts/run_fault_test.sh scale-up          # Teste 3
./fault-tolerance/scripts/run_fault_test.sh multiple-failures # Teste 4
```

**Todos os Testes:**
```bash
./fault-tolerance/scripts/run_fault_test.sh all
```

## üìä Cen√°rios de Teste

### Teste 1: BASELINE - Performance Sem Falhas
**Objetivo:** Estabelecer linha de base de performance

**Configura√ß√£o:**
- Cluster completo (1 master + 2 workers)
- Execu√ß√£o normal de WordCount
- Dataset: 500MB+

**M√©tricas Coletadas:**
- Tempo total de execu√ß√£o
- Throughput (MB/s)
- N√∫mero de containers utilizados
- Status de todos os n√≥s

**Resultado Esperado:**
- Job completa com sucesso
- Todos os n√≥s ativos durante toda execu√ß√£o
- Baseline de tempo para compara√ß√£o

---

### Teste 2: Falha de 1 Worker Durante Execu√ß√£o
**Objetivo:** Testar recupera√ß√£o de falha de n√≥ √∫nico

**Configura√ß√£o:**
- Inicia com cluster completo (2 workers)
- Ap√≥s 30s de execu√ß√£o: **remove hadoop-worker1**
- Job continua com apenas 1 worker

**M√©tricas Coletadas:**
- Tempo at√© detec√ß√£o da falha
- Tempo de recupera√ß√£o
- Tasks perdidas e reexecutadas
- Impacto no tempo total de execu√ß√£o

**Resultado Esperado:**
- YARN detecta falha do NodeManager
- Tasks em execu√ß√£o no worker1 s√£o reprocessadas
- Job completa com sucesso (por√©m mais lento)
- Demonstra failover autom√°tico

---

### Teste 3: Scale Up - Adicionar Worker Durante Execu√ß√£o
**Objetivo:** Testar elasticidade do cluster

**Configura√ß√£o:**
- Inicia com apenas 1 worker (hadoop-worker1)
- Ap√≥s 30s de execu√ß√£o: **adiciona hadoop-worker2**
- Job passa a utilizar recursos adicionais

**M√©tricas Coletadas:**
- Tempo at√© novo n√≥ ser reconhecido
- Redistribui√ß√£o de tasks
- Melhoria de performance ap√≥s scale up

**Resultado Esperado:**
- Novo NodeManager se registra no ResourceManager
- Novas tasks s√£o alocadas no novo n√≥
- Job completa mais r√°pido que execu√ß√£o com 1 worker
- Demonstra adi√ß√£o din√¢mica de recursos

---

### Teste 4: Falhas M√∫ltiplas (Cen√°rio Catastr√≥fico)
**Objetivo:** Testar limite de toler√¢ncia a falhas

**Configura√ß√£o:**
- Inicia com cluster completo (2 workers)
- Ap√≥s 20s: **remove hadoop-worker1**
- Ap√≥s mais 20s: **remove hadoop-worker2**
- Master fica sem workers dispon√≠veis

**M√©tricas Coletadas:**
- Tempo at√© falha total do job
- Comportamento do ResourceManager
- Logs de erro e tentativas de recupera√ß√£o

**Resultado Esperado:**
- Job FALHA ap√≥s timeout
- ResourceManager reporta falta de recursos
- Logs mostram tentativas de retry
- Demonstra limites da toler√¢ncia a falhas

---

## üìà An√°lise de Resultados

### Arquivos de Resultado

Ap√≥s cada teste, os seguintes arquivos s√£o gerados em `fault-tolerance/results/`:

```
test1_baseline.txt          # M√©tricas do baseline
test1_monitor.log           # Log detalhado do monitoramento

test2_worker_failure.txt    # M√©tricas de falha de worker
test2_monitor.log           # Log do comportamento sob falha

test3_scale_up.txt          # M√©tricas de scale up
test3_monitor.log           # Log do comportamento com adi√ß√£o de n√≥

test4_multiple_failures.txt # M√©tricas de falhas m√∫ltiplas
test4_monitor.log           # Log do colapso do cluster
```

### M√©tricas Importantes

**Performance:**
- Tempo total de execu√ß√£o (segundos)
- Compara√ß√£o com baseline (% mais lento/r√°pido)
- Throughput de processamento

**Resili√™ncia:**
- Tempo de detec√ß√£o de falha (segundos)
- Tempo de recupera√ß√£o (segundos)
- Taxa de sucesso de reprocessamento
- N√∫mero de tentativas de retry

**Recursos:**
- N√∫mero de n√≥s ativos durante execu√ß√£o
- Containers em execu√ß√£o
- Utiliza√ß√£o de mem√≥ria YARN
- Distribui√ß√£o de blocos HDFS

### Compara√ß√£o Entre Testes

| Teste | Workers | Condi√ß√£o | Tempo Esperado | Status |
|-------|---------|----------|----------------|--------|
| 1. Baseline | 2 | Normal | ~3-4 min | ‚úì SUCCESS |
| 2. Worker Failure | 2‚Üí1 | Falha em T+30s | ~5-6 min | ‚úì SUCCESS (recovered) |
| 3. Scale Up | 1‚Üí2 | Adi√ß√£o em T+30s | ~4-5 min | ‚úì SUCCESS |
| 4. Multiple Failures | 2‚Üí0 | Falhas T+20s, T+40s | ~1-2 min | ‚úó FAILED |

## üîç Monitoramento em Tempo Real

O script `monitor_job.sh` fornece visualiza√ß√£o em tempo real:

```
==== Monitor de Job Hadoop ====

Application ID: application_1234567890_0001
Estado: RUNNING
Progresso: 45%
Tempo decorrido: 2m 15s

Status do Cluster:
Total Nodes: 2

-------------------------------------------------
[21:30:45] Progress: 45% | State: RUNNING | Elapsed: 135s | Total Nodes: 2
[21:31:00] Progress: 52% | State: RUNNING | Elapsed: 150s | Total Nodes: 1
‚ö† [21:31:05] N√≥ hadoop-worker1 removido - detectada falha
[21:31:20] Progress: 58% | State: RUNNING | Elapsed: 180s | Total Nodes: 1
```

## üõ†Ô∏è Troubleshooting

### Problema: Job n√£o inicia
```bash
# Verificar se os dados est√£o no HDFS
docker exec hadoop-master hdfs dfs -ls /fault-tolerance/input

# Verificar NodeManagers dispon√≠veis
docker exec hadoop-master yarn node -list
```

### Problema: Script n√£o captura Application ID
```bash
# Aumentar sleep para captura do ID
# Editar run_fault_test.sh linha 56: sleep 10 ‚Üí sleep 20
```

### Problema: Workers n√£o se recuperam
```bash
# Restaurar manualmente
docker-compose start hadoop-worker1 hadoop-worker2
sleep 30

# Verificar logs
docker logs hadoop-worker1
docker logs hadoop-worker2
```

## üìù Limpeza

Remover dados e resultados:
```bash
# Limpar dados locais
rm -rf fault-tolerance/data/*.txt

# Limpar HDFS
docker exec hadoop-master hdfs dfs -rm -r /fault-tolerance

# Limpar resultados
rm -rf fault-tolerance/results/*.txt
rm -rf fault-tolerance/monitoring/*.log
```

## üéØ Conclus√µes Esperadas

Este framework demonstra:

1. **Toler√¢ncia a Falhas YARN:**
   - NodeManager pode falhar sem derrubar job
   - Tasks s√£o automaticamente reexecutadas
   - ResourceManager mant√©m estado consistente

2. **Elasticidade:**
   - Cluster aceita novos n√≥s dinamicamente
   - Recursos s√£o redistribu√≠dos automaticamente
   - Melhoria de performance com scale up

3. **Limites:**
   - Perda de todos workers causa falha do job
   - Overhead de recupera√ß√£o impacta performance
   - Trade-off entre resili√™ncia e efici√™ncia

4. **HDFS Resili√™ncia:**
   - Replica√ß√£o protege contra perda de dados
   - Blocos sobrevivem a falhas de DataNode
   - Leitura continua de r√©plicas alternativas
