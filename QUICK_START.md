# Guia RÃ¡pido - Cluster Hadoop

## InÃ­cio RÃ¡pido (5 minutos)

### 1. Iniciar o Cluster

```bash
docker-compose up -d
```

Aguarde ~30 segundos para inicializaÃ§Ã£o completa.

### 2. Verificar Status

```bash
docker-compose ps
```

Todos os 3 containers devem estar "Up".

### 3. Acessar Interfaces Web

- **HDFS NameNode**: http://localhost:9870
- **YARN ResourceManager**: http://localhost:8088
- **JobHistory Server**: http://localhost:19888

### 4. Verificar Cluster

```bash
# Ver DataNodes conectados
docker exec hadoop-master hdfs dfsadmin -report

# Ver NodeManagers ativos
docker exec hadoop-master yarn node -list
```

Deve mostrar 2 DataNodes e 2 NodeManagers.

### 5. Executar Exemplo WordCount

```bash
# Copiar arquivos para container
docker cp examples/wordcount hadoop-master:/tmp/

# Executar job
docker exec hadoop-master bash -c "
  cd /tmp/wordcount
  chmod +x *.py *.sh
  ./run_wordcount.sh
"
```

### 6. Ver Resultados

O script mostrarÃ¡ os resultados automaticamente. VocÃª tambÃ©m pode:

```bash
# Ver resultados manualmente
docker exec hadoop-master hdfs dfs -cat /user/root/wordcount/output/part-*

# Top 10 palavras
docker exec hadoop-master bash -c "
  hdfs dfs -cat /user/root/wordcount/output/part-* | sort -t$'\t' -k2 -nr | head -10
"
```

## ğŸ“š Componentes do Projeto

Este projeto estÃ¡ dividido em trÃªs componentes principais, cada um abordando um aspecto diferente do Apache Hadoop:

### 1ï¸âƒ£ Montagem de um Cluster Hadoop BÃ¡sico (ConfiguraÃ§Ã£o BÃ¡sica)

**Objetivo:** Configurar e executar um cluster Hadoop funcional com Docker.

**LocalizaÃ§Ã£o:**
- `docker-compose.yml` - OrquestraÃ§Ã£o dos containers
- `hadoop-config/` - Arquivos de configuraÃ§Ã£o do Hadoop
- `start-master.sh` e `start-worker.sh` - Scripts de inicializaÃ§Ã£o

**O que foi implementado:**
- âœ… 1 nÃ³ master (NameNode + ResourceManager + JobHistory)
- âœ… 2 nÃ³s workers (DataNode + NodeManager)
- âœ… Interfaces web de monitoramento (portas 9870, 8088, 19888)
- âœ… HDFS com fator de replicaÃ§Ã£o 2
- âœ… YARN configurado com 2GB por NodeManager
- âœ… MapReduce com JobHistory Server

**Como usar:**
```bash
# Iniciar cluster
docker-compose up -d

# Verificar status
docker exec hadoop-master hdfs dfsadmin -report
docker exec hadoop-master yarn node -list

# Acessar interfaces
# HDFS: http://localhost:9870
# YARN: http://localhost:8088
# JobHistory: http://localhost:19888
```

**DocumentaÃ§Ã£o:** Ver `README.md` para detalhes completos da arquitetura.

---

### 2ï¸âƒ£ Teste de Comportamento do Framework Hadoop

**Objetivo:** Demonstrar como diferentes configuraÃ§Ãµes impactam performance e comportamento do HDFS, YARN e MapReduce.

**LocalizaÃ§Ã£o:** `tests/`

**5 Testes Implementados:**

1. **test1_replication.sh** - Fator de replicaÃ§Ã£o HDFS (1, 2, 3)
   - Impacto no uso de disco
   - DistribuiÃ§Ã£o de blocos entre DataNodes
   - Trade-off entre seguranÃ§a e espaÃ§o

2. **test2_yarn_memory.sh** - MemÃ³ria YARN (1GB, 2GB, 4GB)
   - NÃºmero de containers simultÃ¢neos
   - Performance de jobs
   - UtilizaÃ§Ã£o de recursos

3. **test3_scheduler_queues.sh** - Filas do Capacity Scheduler
   - Single queue vs multiple queues (high/default/low)
   - PriorizaÃ§Ã£o de jobs
   - Isolamento de recursos

4. **test4_block_size.sh** - Tamanho de blocos HDFS (64MB, 128MB, 256MB)
   - NÃºmero de map tasks geradas
   - Overhead de metadados no NameNode
   - Performance de I/O

5. **test5_mapreduce_memory.sh** - MemÃ³ria de containers MapReduce
   - MemÃ³ria para mappers e reducers (256MB, 512MB, 1024MB)
   - Paralelismo vs consumo de recursos
   - OtimizaÃ§Ã£o de performance

**Como usar:**
```bash
# Executar teste individual
./tests/scripts/test1_replication.sh all

# Executar todos os testes (~35-40 minutos)
./tests/run_all_tests.sh

# Gerar relatÃ³rio consolidado
./tests/generate_report.sh
```

**Resultados:** Arquivos salvos em `tests/results/` com mÃ©tricas detalhadas e anÃ¡lise comparativa.

**DocumentaÃ§Ã£o:** Ver `tests/README.md` e `tests/TESTING_GUIDE.md` para detalhes de cada teste.

---

### 3ï¸âƒ£ Teste de TolerÃ¢ncia a Falhas e Performance

**Objetivo:** Avaliar resiliÃªncia do Hadoop sob condiÃ§Ãµes adversas e medir capacidade de recuperaÃ§Ã£o.

**LocalizaÃ§Ã£o:** `fault-tolerance/`

**4 CenÃ¡rios de Teste:**

1. **Baseline** - Performance sem falhas
   - Cluster completo (2 workers)
   - ExecuÃ§Ã£o normal de WordCount
   - Estabelece linha de base de tempo (~3-4 min)

2. **Worker Failure** - Falha de 1 worker durante execuÃ§Ã£o
   - Remove hadoop-worker1 apÃ³s 30s
   - Testa recuperaÃ§Ã£o automÃ¡tica do YARN
   - Job deve completar com ~20-40% mais tempo

3. **Scale Up** - AdiÃ§Ã£o dinÃ¢mica de worker
   - Inicia com 1 worker apenas
   - Adiciona worker2 apÃ³s 30s
   - Demonstra elasticidade do cluster

4. **Multiple Failures** - Falhas mÃºltiplas (catastrÃ³fico)
   - Remove ambos workers progressivamente
   - Job deve FALHAR
   - Identifica limites de tolerÃ¢ncia

**Scripts disponÃ­veis:**
- `generate_data.sh` - Gera dataset de 500MB+ para jobs longos
- `upload_data.sh` - Upload para HDFS com verificaÃ§Ã£o
- `monitor_job.sh` - Monitora jobs em tempo real
- `run_fault_test.sh` - Orquestra os 4 testes
- `generate_report.sh` - RelatÃ³rio consolidado com anÃ¡lise

**Como usar:**
```bash
# 1. Gerar dados de teste
./fault-tolerance/scripts/generate_data.sh

# 2. Upload para HDFS
./fault-tolerance/scripts/upload_data.sh

# 3. Executar testes
./fault-tolerance/scripts/run_fault_test.sh all

# 4. Gerar relatÃ³rio
./fault-tolerance/scripts/generate_report.sh
```

**MÃ©tricas coletadas:**
- Tempo de execuÃ§Ã£o e recuperaÃ§Ã£o
- Taxa de sucesso/falha
- Comportamento do ResourceManager
- Logs detalhados de cada cenÃ¡rio

**DocumentaÃ§Ã£o:** Ver `fault-tolerance/README.md` para anÃ¡lise completa dos resultados esperados.

---

## ğŸ¯ Fluxo Recomendado de ExecuÃ§Ã£o

Para executar o projeto completo na ordem correta:

```bash
# Passo 1: Montar cluster bÃ¡sico
docker-compose up -d
docker exec hadoop-master hdfs dfsadmin -report  # Verificar

# Passo 2: Executar testes de comportamento
./tests/run_all_tests.sh                        # ~35-40 min
./tests/generate_report.sh                      # RelatÃ³rio

# Passo 3: Testes de tolerÃ¢ncia a falhas
./fault-tolerance/scripts/generate_data.sh      # Preparar dados
./fault-tolerance/scripts/upload_data.sh        # Upload HDFS
./fault-tolerance/scripts/run_fault_test.sh all # Executar testes
./fault-tolerance/scripts/generate_report.sh    # RelatÃ³rio
```

**Tempo total estimado:** ~50-60 minutos para todos os testes

---

## Comandos Ãšteis

### Gerenciar Cluster

```bash
# Iniciar
docker-compose up -d

# Parar
docker-compose down

# Parar e remover dados
docker-compose down -v

# Ver logs
docker logs hadoop-master
docker logs hadoop-worker1

# Reiniciar
docker-compose restart
```

### Trabalhar com HDFS

```bash
# Acessar container master
docker exec -it hadoop-master bash

# Criar diretÃ³rio
hdfs dfs -mkdir -p /user/root/meudir

# Upload arquivo
hdfs dfs -put arquivo.txt /user/root/meudir/

# Listar arquivos
hdfs dfs -ls /user/root/

# Ver conteÃºdo
hdfs dfs -cat /user/root/meudir/arquivo.txt

# Download arquivo
hdfs dfs -get /user/root/meudir/arquivo.txt ./

# Remover arquivo
hdfs dfs -rm /user/root/meudir/arquivo.txt

# Remover diretÃ³rio
hdfs dfs -rm -r /user/root/meudir
```

### Executar Jobs MapReduce

```bash
# Job WordCount built-in
docker exec hadoop-master bash -c "
  echo 'hello world hello hadoop' > /tmp/input.txt
  hdfs dfs -mkdir -p /input
  hdfs dfs -put /tmp/input.txt /input/
  hadoop jar /opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar \
    wordcount /input /output
  hdfs dfs -cat /output/part-*
"
```

### Monitorar Jobs

```bash
# Listar aplicaÃ§Ãµes YARN
docker exec hadoop-master yarn application -list

# Status de uma aplicaÃ§Ã£o
docker exec hadoop-master yarn application -status <APPLICATION_ID>

# Ver logs de aplicaÃ§Ã£o
docker exec hadoop-master yarn logs -applicationId <APPLICATION_ID>
```

## Estrutura do Projeto

```
trabalho_hadoop/
â”œâ”€â”€ docker-compose.yml              # ConfiguraÃ§Ã£o do cluster
â”œâ”€â”€ hadoop-config/                  # Arquivos de configuraÃ§Ã£o
â”‚   â”œâ”€â”€ core-site.xml              # ConfiguraÃ§Ãµes gerais
â”‚   â”œâ”€â”€ hdfs-site.xml              # HDFS
â”‚   â”œâ”€â”€ yarn-site.xml              # YARN
â”‚   â”œâ”€â”€ mapred-site.xml            # MapReduce
â”‚   â””â”€â”€ workers                    # Lista de workers
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ wordcount/                 # Exemplo WordCount
â”‚       â”œâ”€â”€ mapper.py
â”‚       â”œâ”€â”€ reducer.py
â”‚       â”œâ”€â”€ run_wordcount.sh
â”‚       â””â”€â”€ README.md
â”œâ”€â”€ README.md                       # DocumentaÃ§Ã£o completa
â””â”€â”€ QUICK_START.md                 # Este guia
```

## Recursos do Cluster

- **NÃ³s**: 1 master + 2 workers
- **MemÃ³ria YARN**: 4 GB total (2 GB/worker)
- **CPUs**: 4 vCPUs (2/worker)
- **ReplicaÃ§Ã£o HDFS**: 2 rÃ©plicas

## SoluÃ§Ã£o RÃ¡pida de Problemas

### DataNodes nÃ£o conectam

```bash
# Reiniciar cluster
docker-compose restart

# Ver logs
docker logs hadoop-master
docker logs hadoop-worker1
```

### Job falha

1. Acesse http://localhost:8088
2. Clique no job
3. Veja logs nos containers

### Limpar tudo

```bash
# Parar e remover volumes
docker-compose down -v

# Limpar sistema Docker
docker system prune -a --volumes

# Reiniciar
docker-compose up -d
```

## PrÃ³ximos Passos

1. âœ… Cluster funcionando
2. âœ… Exemplo WordCount executado
3. ğŸ“ Criar seu prÃ³prio job MapReduce
4. ğŸ“ Processar datasets maiores
5. ğŸ“ Experimentar com mÃºltiplos reducers
6. ğŸ“ Implementar outros algoritmos (sorting, join, etc.)

## Recursos Adicionais

- **README.md**: DocumentaÃ§Ã£o completa
- **examples/wordcount/README.md**: Detalhes do exemplo
- Interfaces web para monitoramento
- Logs em tempo real via `docker logs`

## Entrega do Trabalho

Para documentar sua entrega, inclua:

1. âœ… Arquivos de configuraÃ§Ã£o (`hadoop-config/`)
2. âœ… Docker Compose configurado
3. âœ… Screenshots das interfaces web
4. âœ… Exemplo de job executado
5. âœ… DocumentaÃ§Ã£o dos arquivos

Tire screenshots de:
- http://localhost:9870 (HDFS com 2 DataNodes)
- http://localhost:8088 (YARN com job executado)
- http://localhost:19888 (JobHistory)
- SaÃ­da do comando `hdfs dfsadmin -report`
- Resultado do WordCount

Boa sorte! ğŸš€
